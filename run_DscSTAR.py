# -*- coding: utf-8 -*-
"""run_demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LMvq5M0hW3EYdvHoN22G5idD9j-XbRqV
"""

#!/usr/bin/env python
import argparse
import torch.utils.data
import numpy as np
import random
import matplotlib.pyplot as plt
from DscSTAR import training, save_decoder_output
from pre_processing import pre_processing

seed = 0
random.seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.manual_seed(seed)

prep = 'mc'
ae_type = 512 #512
batch_size = 300 # batch size for each cluster
num_epochs = 400
base_lr = 1e-3
lr_step = 40  # step decay of learning rates
momentum = 0.9
l2_decay = 2e-5
gamma = 10.0  # 10-50 regularization between reconstruction and transfer learning
log_interval = 20

# CUDA
device_id = 0 # ID of GPU to use
cuda = torch.cuda.is_available()
if cuda:
    torch.cuda.set_device(device_id)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

pre_process_paras = {'prep': prep}
nn_paras = {'ae_type': ae_type, 'batch_size': batch_size, 'num_epochs': num_epochs,
            'base_lr': base_lr, 'lr_step': lr_step,
            'momentum': momentum, 'l2_decay': l2_decay, 'gamma': gamma,
            'cuda': cuda, 'log_interval': log_interval}

plt.ioff()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Run scSTAR_K')
    parser.add_argument('--data-folder', default='/content/drive/MyDrive/DscSTAR/inputs/', help='Path to the data folder')
    parser.add_argument('--input-file1', default='Case_corrected.csv', help='First input csv file name')
    parser.add_argument('--input-file2', default='Ctr_corrected.csv', help='Second input csv file name')
    parser.add_argument('--output-folder', default='/content/drive/MyDrive/DscSTAR/outputs/', help='Path to the output folder')
    parser.add_argument('--output-name1', default='Case_DscSTAR.csv', help='First output csv file name')
    parser.add_argument('--output-name2', default='Ctr_DscSTAR.csv', help='Second output csv file name')
    args = parser.parse_args()

    data_folder = args.data_folder
    dataset_file_list = [args.input_file1, args.input_file2]
    dataset_file_list = [data_folder + f for f in dataset_file_list]

    dataset, muX = pre_processing(dataset_file_list, pre_process_paras)
    nn_paras['num_inputs'] = len(dataset['gene_sym'])
    plotpath = args.output_folder + "UMAP.png"
    plotpath2 = args.output_folder + "LOSS.png" 

    # training
    model, classifier, loss_total_list, loss_reconstruct_list, loss_transfer_list, loss_ortho_list = training(dataset, nn_paras, plotpath2)

    # output
    output_file1 = args.output_folder + args.output_name1
    output_file2 = args.output_folder + args.output_name2
    
    save_decoder_output(model, dataset, muX, output_file1, output_file2, plotpath)
    
    model_save_path = args.output_folder + 'trained_model.pth'

    model.eval() 
    torch.save(model, model_save_path) 

